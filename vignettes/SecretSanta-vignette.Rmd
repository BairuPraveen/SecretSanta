---
title: 'SecretSanta: flexible pipelines for functional secretome prediction'
author: "Anna Gogleva"
date: '`r Sys.Date()`'
output: rmarkdown::html_vignette
tables: yes
bibliographystyle: unsrt
bibliography: Santa.bib
vignette: >
    %\VignetteEngine{knitr::knitr}
    %\VignetteIndexEntry{SecretSanta vignette}
    %\usepackage[UTF-8]{inputenc}  
---  

## 1. Background
The **SecretSanta** package provides an R interface for the integrative
prediction of extracellular proteins that are secreted via classical pathways.

Secretome prediction often involves multiple steps. Typically, it starts with 
prediction of short signal peptides at the N-terminal end of a protein
(**Figure 1 a**). Next, it is crucial to ensure the absence of motifs and
domains preventing the protein from being secreted despite the presence of the 
signal peptide. These sequences include transmembrane domains, short ER lumen
retention signals and mitochondria/plastid targeting signals
(**Figure 1 b-d**). The ultimate aim of a secretome prediction pipeline is to 
identify secreted proteins as shown in **Figure 1 a** and filter out
those shown in **Figure 1 b-d**.

\newline

```{r motifs, out.width = "400px", fig.align = "center", echo = FALSE}
knitr::include_graphics("motifs_and_domains.png")
```

> **Figure 1.** Characteristic motifs, domains and their arrangements, helping to distinguish extracellular proteins from proteins retained inside the cell.

\newline

A number of command line tools and web-interfaces are available to perform predictions of individual motifs and domains
([signalp](http://www.cbs.dtu.dk/services/SignalP/),
[targetp](http://www.cbs.dtu.dk/services/TargetP/),
[TMHMM](http://www.cbs.dtu.dk/services/TMHMM/),
[TOPCONS](http://topcons.net/),
[WolfPsort](https://github.com/fmaguire/WoLFPSort)), however the interface 
allowing to combine the outputs in a single flexible workflow is lacking.

\newline

The **SecretSanta** package attempts to bridge this gap. It provides wrapper and parser
functions around existing command line tools for predictions of signal peptides
and protein subcellular localization. The functions are designed to work 
together by producing standardized output as an instance of ``CBSResult``
superclass.

\newline 

Objects of ``CBSResult`` class contain an ``in_fasta`` slot with 
the initial submitted sequences and an ``out_fasta`` slot with positive candidates after the method application. Each particular method then complements this simple structure with relevant slots. For example, outputs of the ``signalp`` function are organised in ``SignalpResult`` objects. 
Within ``CBSResult`` class objects all fasta slots are organised in `AAStringSetList` . `in_fasta` and `out_fasta` slots could be extracted separetely with designated accessor functions `getInfasta` and `getOutfasta`. Alternatively, all fasta
fasta slots could be extracted with `getFastas` method as an instance of `AAStringSetList` class, which makes it possible to apply all the defined 
`AAStringSetLisst` methods to this object.
Apart from ``in_fasta`` and ``out_fasta`` slots inherited from ``CBSResult`` class, ``SignalpResult`` objects contain three additional slots, relevant for the **signalp** method:

+ ``sp_tibble`` - parsed **signalp** tabular output for positive candidates;
+ ``mature_fasta`` - mature sequence for the candidate secreted proteins, i.e 
sequences with cleaved N-terminal signal peptides;
+ ``sp_version`` - version of **signalp** used to generate this object.

The detailed organisation of class structure is shown in the **Figure 2**. 

```{r objects, out.width="600px", fig.align="center", echo=FALSE}
knitr::include_graphics("class_structure.png")
```

> **Figure2.** SecretSanta S4 class structure.

\newline

This allows the user to easily pipe results between individual predictors to
create flexible custom pipelines and also to compare predictions between similar
methods. For instance, **targetp** and **WoLFPsort** for subcellular 
localization and multiple versions of **signalp** for signal peptide prediction.

\newline

To speed-up processing of large input fasta files initial steps of the pipeline
are automatically run in parallel when the number of
input sequences exceeds a certain limit. 

\newline

Taken together **SecretSanta** provides a platform to build automated multi-step secretome prediction pipelines that can be applied to large protein sets to
facilitate comparisons of secretomes across multiple species or under various conditions. For example, an earlier draft of this package was successfully used to compare the secreted protein complement of a plant pathogen throughout an infection time-course in plant roots [@Evangelisti2017].

\newline 

To avoid confusion, the names of external command line tools will
be shown in **bold**, and the corresponding R functions from the **SecretSanta**
package will have standard ``code highlighting``. For example:

+ **signalp** - CBS signalp and its associated derivative files;
+ ```signalp``` - **SecretSanta** wrap function around **signalp**;

Majority of the **SecretSanta** functions could be run in 2 modes: 

+ ``starter`` - when initiating the secretome pipeline with the above
function;
+ ``piper`` - for downstream/intermediate steps, so that the function expects an
output from another wrapper function.

## 2. Installation of external dependencies

**SecretSanta** relies on a set of existing command line tools to predict secreted proteins. Please install them and configure according to the listed instructions. Due to limitations imposed by the external dependencies, some of **SecretSanta** wrapper functions are fully fuctional only on Linux systems.

\newline

### 2.1 Download and configure external dependencies

#### Tools for prediction of signal peptides and cleavage sites:
- **signalp-2.0** 
    + This version can run under IRIX, IRIX64, Linux, OSF1, SunOS.
    + Download stand alone signalp2.0 
    http://www.cbs.dtu.dk/cgi-bin/sw_request?signalp+2.0
    + Unpack the archive
    ```{sh unpack signalp-2.0, eval=FALSE}
    tar -zxvf signalp-2.0.Linux.tar.Z
    cd signalp-2.0
    ```
    + Edit "General settings" at the top of the **signalp** file. Set value 
    of 'SIGNALP' variable to be path to your **signalp-2.0** directory.
    Other variables usually do not require changes. We will not use plotting 
    functions from signalp, so gnuplot, ppmtogif and ghostview are not required.
    For more details please check ``signalp-2.0.readme``.
    + Since we want to be able to run different versions of **signalp**,
    including the legacy versions, it is important to be able to discriminate
    between them. R is oblivious to shell aliases, so we will simply rename the
    **signalp** script:
    
    ```{sh rename signalp2, eval = FALSE}
    mv signalp signalp2
    ```

\newline

- **signalp-3.0** 
    + This version will run on the most common UNIX platforms.
    + Download stand alone signalp3.0 
    http://www.cbs.dtu.dk/cgi-bin/sw_request?signalp+3.0
    + Unpack the archive
    ```{sh unpack signalp-3.0, eval=FALSE}
    tar -zxvf signalp-3.0.Linux.tar.Z
    cd signalp-3.0
    ```
    + Similar to **signalp-2.0**, edit "General settings" at the top of the 
    signalp file. Set value of 'SIGNALP' variable to be path to your
    **signalp-3.0** directory. Other variables usually do not require changes. 
    For more details please check ``signalp-3.0.readme``.
    + Rename **signalp** script to avoid further confusion between the versions:
    ```{sh rename signalp3, eval = FALSE}
    mv signalp signalp3
    ```
    
\newline

- **signalp-4.1** - the most recent version
    + This version can run under Windows, OS X (Macintosh) and Linux.
    + Download stand alone signalp4.1 
    http://www.cbs.dtu.dk/cgi-bin/nph-sw_request?signalp
    + Unpack the archive
    ```{sh unpack signalp-4.1, eval = FALSE}
    tar -zxvf signalp-4.1.Linux.tar.Z
    cd signalp-4.1
    ```
    + Edit "General settings" at the top of the **signalp** file. Set values for
    'SIGNALP' and 'outputDir' variables. For more details please check
    ``signalp-4.1.readme``.
    + Rename **signalp** script to avoid further confusion between the versions:
    ```{sh rename signalp4, eval = FALSE}
    mv signalp signalp4
    ```

\newline

#### Tools for prediction of protein subcellular localization:    
    
- **targetp-1.1**
    + **targetp-1.1** will run on the most common UNIX platforms  
    + Download stand alone targetp 
    http://www.cbs.dtu.dk/cgi-bin/nph-sw_request?targetp
    + Unpack the archive:
    ```{sh unpack targetp-1.1, eval = FALSE}
    tar -zxvf targetp-1.1b.Linux.tar.Z 
    cd targetp-1.1
    ```
    + Edit the paragraph labeled "GENERAL SETTINGS, customize" at the top of 
    the **targetp** file.
    Set values for 'TARGETP' and 'TMP' variables. Ensure, that the path to
    **targetp** does not exceed 60 characters, otherwise **targetp-1.1** might 
    fail.

\newline

- **WoLFPsort**
    + Clone WoLFPsort
    ```{sh, download WoLFPSort, eval = FALSE}
    git clone https://github.com/fmaguire/WoLFPSort.git
    cd WoLFPSort
    ```
    + Copy the binaries from the appropriate platform specific binary directory
    ```./bin/binByPlatform/binary-?``` to ```./bin/```
    + For more details please check the ```INSTALL``` file.
    + The most important script we need **runWolfPsortSummary** has a bulky 
    name, we will rename it to **wolfpsort** for future convenience:
    ```{sh rename wolf, eval = FALSE}
    mv runWolfPsortSummary wolfpsort
    ```

\newline

#### Tools for predicting transmembrane domains
- **tmhmm-2.0**
    + **tmhmm-2.0** will run on the most common UNIX platforms  
    + Download stand alone tmhmm 
    (http://www.cbs.dtu.dk/cgi-bin/nph-sw_request?tmhmm)
    + Unpack the archive:
    ```{sh, unpack tmhmm-2.0, eval = FALSE}
    tar -zxvf tmhmm-2.0c.Linux.tar.gz
    cd tmhmm-2.0c
    ```
    + Set correct path for Perl 5.x in the first line of ```bin/tmhmm``` and
    ```bin/tmhmmformat.pl``` scripts.
    + For more details please check the ```README``` file.
    
\newline

### 2.2 Organise access to the external dependencies

Two options are possible:

#### Option A: all the external dependencies are accessible from any location.

This requires modification of ``$PATH`` environment variable. To make the change permanent, edit ``.profile``:

Open ./profile:
```{sh edit $PATH, eval = FALSE}
gedit ~/.profile
```

Add a line with all the path exports.
In this example all the dependencies are installed in the `my_tool` directory:
```{sh, eval = FALSE}
export PATH=
"/home/my_tools/signalp-4.1:\
/home/my_tools/signalp-2.0:\
/home/my_tools/signalp-3.0:\
/home/my_tools/targetp-1.1:\
/home/tmhmm-2.0c/bin:\
/home/my_tools/WoLFPSort/bin:\
$PATH"
```

Reload ``.profile``:
```{sh, eval = FALSE}
. ~/.profile
```

Reboot to make changes visible to R. Alternatively - restart the R session.

#### Option B: paths to external dependencies are supplied in a separate file:
This option should be used when ``$PATH`` variable can not be modified. Create 
a 2-column space-separated text file with listed paths for all the external
dependencies.  Please note, if you follow this route you can avoid renaming
executable for multiple versions of **signalp**.

```{r load SecretSanta, message=FALSE, echo = FALSE}
library(SecretSanta)
```

```{r paths example, echo = FALSE}
pp <-
    suppressMessages(read.table(
    system.file("extdata", "santa_paths",
    package = "SecretSanta"),
    sep = ' ',
    header = FALSE
    ))
    names(pp) <- c('tool', 'path')
    
    knitr::kable(pp,
    format = 'pandoc',
    caption = "**Table1**: Sample paths to external dependencies")
```

For external tool names please use simple character strings without version 
numbers. The only exception here are different versions of **signalp**, which
require version number in one-digit format in the ``tool`` column to be
distinguishable.


### 2.3 Check that all the required dependencies are installed correctly
```{r real load SecretSanta, message=FALSE}
library(SecretSanta)
```
The ```manage_paths``` function will run small test jobs to check that all the
external dependencies are functional.

In case all the dependencies are available globally (see **Option A**):
```{r check_paths_in_path, echo = TRUE, collapse = TRUE, eval = FALSE}
check1 <- manage_paths(in_path = TRUE)
```
It is also possible to run just a single test for a specific dependency in 
question:

```{r check_paths_in_path_single, echo = TRUE, collapse = TRUE}
check1 <- manage_paths(in_path = TRUE, test_tool = 'signalp2')
```

In case we have paths organised in a separate file (see **Option B**):

```{r check_path_in_file, echo = TRUE, collapse = TRUE, eval = FALSE}
check2 <- manage_paths(
    in_path = FALSE,
    path_file = system.file("extdata",
    "sample_paths",
    package = "SecretSanta")
    )
```

Note: ```manage_paths``` is case insensitive and will convert all the tool 
names to the lower case. 


## 3. Individual methods

### 3.1 Signalp

**signalp** is a software tool to predict classical signal peptides and 
cleavage sites [@Nielsen1997] in eukaryotes and bacteria. The method combines
prediction of signal peptides and cleavage cites based on a combination of
artificial neural networks and hidden Markov models. The latter can distinguish between signal peptides and non-cleaved signal anchors 
[@Nielsen1997].

Currently ```signalp``` function from SecretSanta provides an interface for the 
three recent versions of  **signalp**. The reason behind this is that
**signalp-4** and **signalp-4.1** are not sensitive enough to predict certain
classes of secreted oomycete and fungal effectors [@Sperschneider2015]. Thus,
providing access to the older versions allows greater flexibility for building 
versatile prediction pipelines for a wider taxonomic range of species.

- **signalp-2.0** [@Nielsen1998]
- **signalp-3.0** [@Bendtsen2004]
- **signalp-4.0** [@Petersen2011]

``signalp`` requires specifying ``organism`` argument; possible values include:

+ *'euk'* - for eukaryotes;
+ *'gram+'* - for gram-positive bacteria;
+ *'gram-'* - for gram-negative bacteria.

To run ``signalp`` prediction, first read fasta file with amino acid sequences 
and store its contents in a separate variable:
```{r read aa fasta, }
aa <- readAAStringSet(system.file("extdata", "sample_prot_100.fasta",
                                    package = "SecretSanta"))
```
Initialize object of CBSResult class with ```aa``` as ```in_fasta``` attribute.
```{r initialise CBSResult, cache=FALSE}
inp <- CBSResult(in_fasta = aa)
inp
```
Since this is the first step in our secretome prediction pipeline, we will run
``signalp`` in a *starter* mode. Here we select version number 2
(**signalp-2.0**) and assume that signalp is accessible globally, so no path 
files should be specified. If **signalp** can not be accessed globally, this 
will result in an error message.

```{r run signalp2,  collapse = TRUE, }
step1_sp2 <- signalp(inp, version = 2,
                    organism = 'euk',
                    run_mode = "starter",
                    legacy_method = 'hmm')
```

The above code under the hood runs **signalp-2.0** prediction and outputs
result as an instance of ```SignalpResult``` class, which belongs to a more 
generic ``CBSResult()`` superclass having just 2 slots: ``in_fasta`` and 
``out_fasta``.

```{r explain SignalpResult class}
class(step1_sp2)
slotNames(step1_sp2)
```

The ```SignalpResult``` object contains 5 slots:

+ ``in_fasta`` - original set of input amino acid sequences;

+ ``sp_tibble`` - parsed **signalp** tabular output for positive candidates;

+ ``out_fasta`` - full length amino acid sequences of positive candidates;

+ ``mature_fasta`` - mature sequence for the candidate secreted proteins, i.e 
sequences with cleaved N-terminal signal peptides;

+ ``sp_version`` - version of **signalp** used to generate this object.

You can use accessor methods to get contents of individual slots:

```{r get input fasta}
getInfasta(step1_sp2)
```
Please note that ``signalp`` truncates all the input sequences
longer than 2000 a.a, by default. In this case '_truncated' is added to the original sequence ids to keep track of the changes. An alternative option is to discard long sequences completely before the analysis, to do so set
``truncate = FALSE`` when running ``signalp``.

```{r showcase all other accessors for SignalpResult object}
getSPtibble(step1_sp2)
getOutfasta(step1_sp2)
getMatfasta(step1_sp2)
getSPversion(step1_sp2)
```

Next, imagine we would like to run all the **signalp** version on the same input
for comparison. We can do this by simply changing ``version`` value:

```{r run signalp3 and 4, collapse = TRUE, }
step1_sp3 <- signalp(inp, 
                    version = 3,
                    organism = 'euk',
                    run_mode = "starter",
                    legacy_method = 'hmm')
step1_sp4 <- signalp(inp,
                    version = 4,
                    organism = 'euk',
                    run_mode = "starter")
```
In this case ``signalp-4.1`` version resulted in fewer candidates. 
Please note, that despite differences in the output format generated by 
multiple versions of **signalp**, ``signalp`` returns ``sp_tibble`` in a 
standard format.

In order to pipe result from different versions of **signalp** just switch to
the ``run_mode = 'piper'`` for the second and other downstream steps. In this
case ``signalp`` will run the analysis using contents of ``out_fasta`` slot as
an input. Say, we want to do the following piping:
**signalp2** -> **signalp3** -> **signalp4**.

\newline

We will re-use the ``step1_sp2`` object generated earlier in the ``starter`` mode for the **signalp2** -> **signalp3** piping operation:

```{r signalp piper sp2->sp3, collapse = TRUE}
step2_sp3 <- signalp(step1_sp2,
                    version = 3,
                    organism = 'euk',
                    run_mode = 'piper',
                    legacy_method = 'hmm')
```

Similar with the **signalp3** -> **signalp4** piping:

```{r signalp piper sp3 -> sp4, collapse = TRUE}
step3_sp4 <- signalp(step2_sp3,
                    version = 4,
                    organism = 'euk',
                    run_mode = "piper")
```

With the input fasta files containing more than 1000 sequences, ``signalp`` 
will automatically switch to parallel mode. It will split the input into 
smaller chunks and run prediction as an embarrassingly parallel process using
specified number of CPUs (see ``cores`` argument). Execution time depends on
the number of CPUs available and the input file size. With 48 CPUs it takes ~2
minutes to run ``signalp`` on the input fasta file with more than 40'000
sequences.

### 3.2 Tmhmm
**TMHMM** predicts transmembrane a-helices and identifies integral
membrane proteins based on HMMs [@Krogh2001; Sonnhammer1998]. It is important
to exclude proteins with transmembrane domains located after signal peptide, as
they will be retained in the membrane. Since **TMHMM** is often unable to
distinguish between N-terminal signal peptides and transmembrane domains, it is
recommended to run ``tmhmmm`` on the mature sequences obtained after running 
``signalp`` function.

``tmhmm`` function can handle input objects of ``SignalpResult`` class with 
non-empty ``mature_fasta`` slot.

Here we will use output of the ``signalp`` function as an input for ``tmhmm``:

```{r tmhmm legal, collapse=TRUE, cache=FALSE}
tm <- tmhmm(step1_sp2, TM = 0)
```
Attempts to run ``tmhmm`` on the ``CBSResult`` object lacking ``mature_fasta`` 
slot will produce an error:

```{r tmhmm illegal, collapse=TRUE, error=TRUE}
tm2 <- tmhmm(inp, TM = 0)
```

``tmhmm`` outputs instances of ``TMhmmResult`` class, inheriting from 
``CBSResult``.

```{r explain TMhmmResult class}
class(tm)
slotNames(tm)
```

``TMhmmResult`` object contains 5 slots:

+ ``in_fasta`` and ``out_fasta`` are common attributes of all classes 
inheriting from the ``CBSResult`` class;

+ ``tm_tibble`` - parsed **tmhmm** tabular output for candidates not having more
transmembrane domains than specified by ``TM`` threshold;

+ ``in_mature_fasta`` - mature sequences used as an input for ```tmhmm```

+ ``out_mature_fasta`` - outputted mature sequences not having more 
transmembrane domains than specified by ``TM`` threshold.

To get contents of individual slots you could use accessor functions:

```{r accessors for TMhmmResult class}
getTMtibble(tm)
getInMatfasta(tm)
getOutMatfasta(tm)
```
### 3.3 Topcons
### 3.4 Targetp
**Targetp** predicts the subcellular localization of secreted eukaryotic proteins based on the presence of signal peptide (SP), chloroplast transit peptides (cTP) or mitochondrial targeting peptides (mTP) in the N-terminus [@Emanuelsson2008]. 
Including **targetp** in the pipeline can provide additional evidence that a 
protein with a predicted signal peptide is not targeted to plastids or
mitochondria and is indeed extracellular. The ``targetp`` function accepts input objects belonging to the ``CBSResult`` class uses `out_fasta` slot as a direct input to the **targetp** method, i.e, predictions are based on the full
protein sequences, not their mature versions.

``targetp`` requires specifying ``network_type`` to run correctly. Possible 
values include:

- *'P'* - for plants;
- *'N'* - for non_plants.

It is possible to run ``targetp`` in both *piper* and *starter* modes.
Imagine, we want to start our pipeline by running ``targetp`` using already
created ``inp`` object as an input:

```{r tatgetp starter, collapse = TRUE, cache=FALSE}
tp <- targetp(inp,
        network = 'N',  # for non-plant networks
        run_mode = 'starter')
```

Alternatively, we can run targetp on the output of other functions, for example
``signalp`` in the *piper* mode:

```{r targetp piper, collapse = TRUE, cache=FALSE}
tp_pipe <- targetp(step1_sp2,
                    network = 'N',
                    run_mode = 'piper')
```

In both cases ``targetp`` will output an object of ``TargetpResult`` class with 
the following slots:

```{r explain TargetpResult class}
class(tp)
slotNames(tp)
```

+ ``in_fasta`` and ``out_fasta`` are common attributes of all classes 
inheriting from ``CBSResult`` class;
+ ``tp_tibble`` - parsed tragetp tabular output for candidates not targeted
to mitochondria or plastids, i.e most likely to be secreted.

To access the ``tp_tibble`` slot use the ``getTPtibble`` method:
```{r access tp_tibble}
getTPtibble(tp)
```

``targetp`` will automatically switch to a parallel mode if the number of input
sequences is greater than 1000.

### 3.5 Wolfpsort
**WoLFPSORT** - predicts protein subcellular localization based on the PSORT
principle. It converts amino acid sequences into numerical localization 
features based on sorting signals, amino acid composition and functional motifs.
The converted data is then classified based on k-nearest neighbor algorithm 
[@Horton2006].

``wolfpsort`` requires ``organism`` parameter. Possible values include:

- *'plant'*;
- *'animal'*;
- *'fungi'*.

The ``wolfpsort`` function accepts objects of ``CBSResult`` class, and could be
run in both `starter` and `piper` modes.

```{r run wolfpsort, collapse = TRUE, cache=FALSE}
wlf <- wolfpsort(step1_sp2, organism = 'fungi', run_mode = 'piper')
```

``wolfpsort`` returns an object with 3 slots:

```{r explain WolfpsortResult class}
class(wlf)
slotNames(wlf)
```
+ ``in_fasta`` and ``out_fasta`` are common attributes of all classes 
inheriting from ``CBSResult`` class;
+ ``wolf_tibble`` - parsed WoLFPsort tabular output for sequences with 
'extracellular' predicted to be the most probable subcellular localization.

To access contents of the ``wolf_tibble`` slot use ``getWOlFtibble`` method:
```{r access wolf_tibble}
getWOLFtibble(wlf)
```

Since ``wolfpsort`` has the same purpose as ``targetp`` it might be useful to
run these functions side by side to compare the obtained results
(see [targetp results](#Targetp)).

### 3.6 Check the presence of terminal ER-retention motifs
In addition to having signal peptides, some proteins have an ER-retention 
signal in the C-terminal domain that prevents protein from being secreted outside the cell. There are at least 2 known ER-retention motifs (*KDEL* and *HDEL*) [@Munro1987].

The ``check_khdel`` function uses simple pattern matching to scan amino acid
sequences and remove those with an ER retention signal in the C-terminus. To run
it, simply pass a ``CBSResult`` object as an input.  ``check_khdel`` function will 
You can run ``check_khdel``
in either *piper* or *starter* mode. Since it only makes sense to check ER-retention signals in proteins with signal peptides, ``check_khdel`` function can be used only in the middle of pipelines, and is restricted to the default `piper` behaviour. The function does not rely on external 
dependencies, so providing path container is not required.

```{r check ER retention, collapse = TRUE, cache=FALSE}
er_result <- check_khdel(step1_sp2, pattern = 'prosite')

```
This will return an object with 3 slots:

```{r explain ErResult class}
slotNames(er_result)
```
+ ``in_fasta`` and ``out_fasta`` are common attributes of all classes 
inheriting from ``CBSResult`` class;
+ ``retained_fasta`` - all the sequences with C-terminal '(K/H)DEL' motifs, in case 
you would like to have a look at them.

### 3.7 M-slicer

This is an experimental option. The ``m_slicer`` function takes the input amino acid sequences and generates all possible subsequences starting with methionine based on the assumption that translation start sites might be mis-predicted in the original set of proteins, which in turn would result in signal peptides also being mis-predicted. The output of this step can be used as an input for secretome prediction pipelines to rescue secreted proteins with mis-predicted start sites. (Making a list and checking it twice...just like Santa does). Sequence ids for the newly generated slices are built by concatenating original sequence ids, 'slice' string and position of the methionine sliced from. For example: 
``ALI_PLTG_3_slice_M86`` means that ``ALI_PLTG_3`` sequence was sliced starting
from the methionine in the position 86.

``m_slicer`` has 2 running modes:

+ ``slice`` - to simply slice input fasta regardless of it's origin;

```{r m_slicer slice, cache=FALSE}
slice <- m_slicer(aa,  # a set of amino acid seqeunces
                run_mode = 'slice',
                min_len = 100 # minimal length of the outputed slices
)
```

+ ``rescue`` - having output from any other up-stream function it extracts 
proteins not predicted to be secreted on the initial run and generate slices for
them.

```{r m_slicer rescue, cache=FALSE}
rescued <- m_slicer(step1_sp2,  # signalp2 output
                run_mode = 'rescue',
                min_len = 100)
```

Results of both run modes could be used as an input for other ``SecretSanta`` 
predictors. Say, we want to run ``signalp`` on the rescued proteins. Note, that 
``m_slicer`` outputs ``AAStringSet`` objects, so in order to pass it to
``signalp`` we first need to create ``CBSResult`` object with 
``in_fasta = rescued``.

```{r signalp for rescued proteins, collapse = TRUE, cache=FALSE}
r_inp <- CBSResult(in_fasta = rescued)
sp_rescue <- signalp(r_inp,
                    version = 2,
                    organism = 'euk',
                    run_mode = 'starter',
                    truncate = TRUE,
                    legacy_method = 'hmm')
```
The slicing procedure returned 15 additional potentially secreted candidates.

## 4. Pipers and/or starters

Here is a short summary of individual methods available via the **SecretSanta**
package:

```{r starters_pipers, echo = FALSE}
st <- suppressMessages(read.table(system.file("extdata",
                                    "summary_tools.csv",
                                    package = 'SecretSanta'),
                        sep = ',', header = TRUE))

knitr::kable(st, align = c(rep('c', 2), 'l', rep('c',3)),
                caption = "**Table2**: Individual methods summary.")
```

## 5. Build pipelines

We are now ready to build a pipeline using all of our available methods. 
Say, we would like to have a relatively short pipeline (**Figure 3**) with the
following analytic steps:

+ use **signalp4** to predict signal peptides and cleavage sites;
+ run **tmhmm** on the output, to ensure that predicted proteins with
signal peptides do not contain TM domains, i.e won't be stuck in the membrane;
+ run **targetp** on the output, to make sure that a set of selected proteins
is not targeted to plastids or mitochondria;
+ collect the targetp output and scan for ER-retention signals - to ensure
that proteins won't be stuck in the ER.


```{r pipe1, out.width = "200px", fig.align="center", echo = FALSE}
knitr::include_graphics("pipes_short.png")
```

> **Figure 3**: Minimal pipeline for secretome prediction

Now we will run this pipeline using ``SecretSanta`` functions, starting with
``aa`` - an ``AAStringSet`` object containing 100 amino acid sequences.

#### Step 1: predict signal peptides

```{r, collapse = TRUE}
input <- CBSResult(in_fasta = aa)

input
step1_sp4 <- signalp(input,
                    version = 4,
                    organism = 'euk',
                    run_mode = 'starter',
                    truncate = TRUE
                    )

getSPtibble(step1_sp4)

getOutfasta(step1_sp4)

getMatfasta(step1_sp4)
```

***
> **Result**: 5 candidate proteins with signal peptides.

#### Step 2: check for presence of TM domains in mature peptides:

```{r, collapse = TRUE}
# we allow 0 TM domains in mature peptides
step2_tm <- tmhmm(step1_sp4, TM = 0)

getTMtibble(step2_tm)

getOutfasta(step2_tm)

getOutMatfasta(step2_tm)

```

***
> **Result**: 5 candidate proteins with signal peptides; 0 TM domains in
mature sequences.

#### Step 3: predict sub-cellular localization
Here we are using ``targetp``, we could have also used ``wolfpsort``.

```{r, collapse=TRUE}
step3_tp <- targetp(step2_tm, network = 'N',run_mode = 'piper')

getTPtibble(step3_tp)

getInfasta(step3_tp)

getOutfasta(step3_tp)
```

This step allowed us to filter 1 sequence potentially targeted to mitochondria.

> **Result**: 4 candidate proteins with signal peptides; 0 TM domains in
mature sequences; not targeted to plastids or mitochondria.

#### Step 4: check for ER-retention signals

```{r, collapse = TRUE}
step4_er <- check_khdel(step3_tp, 'elm')
getOutfasta(step4_er)
```

***
> **Final Result**: 4 candidate proteins with signal peptides; 0 TM domains in
mature sequences; not targeted to plastids or mitochondria; not retained in ER.

This is an example of a fairly simple pipeline, but you can create more complex
ones. A more stringent pipeline might involve multi-step filtration on signal
peptide prediction as well as additional predictions for 'rescued'
(**Figure 4**) sequences.

```{r pipe2, out.width = "300px", fig.align="center", echo = FALSE}
knitr::include_graphics("pipes_long.png")
```

> **Figure 4**: Example of a stringent pipeline.

#### Step 5: save the result secretome

```{r, echo = TRUE}
writeXStringSet(getOutfasta(step4_er), 'secretome_out.fasta')
```

#### Compact pipelienes:

Now, once we have examined all the individual analytic steps, we can directly combine them in a single command by using ``%>%`` operator:

```{r, echo = TRUE, collapse = TRUE}
pipeline <- signalp(input, version = 4, organism = 'euk', run_mode = 'starter') %>% 
    tmhmm(TM = 0) %>%
    targetp(network = 'N', run_mode = 'piper') %>%
    check_khdel(pattern = 'prosite')
```

Since ``pp`` belongs to the ``CBSResult`` class, we can again extract the output fasta field and save it in a separate file:

```{r, echo = TRUE, collapse = TRUE}
writeXStringSet(getOutfasta(pipeline), 'secretome_out.fasta')
```

## 6. Running pipelines on HPCs
Now we will download all available fungal proteomes using [``biomartr``](https://cran.r-project.org/web/packages/biomartr/index.html) package and apply the same standard secretome prediction pipleine. To speed-up the process, we will use 20 cores available on our local HPC. Please note, retrival of proteomes might take a while.

```{r, eval = FALSE}
library(biomartr)
meta.retrieval(kingdom = "fungi", db = "refseq", type = 'proteome', 
               path = "fungi_refseq_proteomes")

proteomes <- list.files("fungi_refseq_proteomes/",
                        full.names = TRUE, pattern ="*.fasta")

hpc_pipeline <- function(proteome) {
    input <- CBSResult(in_fasta = readAAStringSet(proteome))
    pipeline <- signalp(input, version = 4, organism = 'euk',
                        run_mode = 'starter') %>% 
        tmhmm(TM = 0) %>%
        targetp(network = 'N', run_mode = 'piper', cores = 20) %>%
        check_khdel(pattern = 'prosite')
    base_proteome <- stringr::str_split(proteome, '/') %>% tail(n = 1)
    writeXStringSet(getOutfasta(pipeline),
                    paste(base_proteome, 'secretome.fasta',
                          sep = '_'))

}

sapply(proteomes, hpc_pipeline)

```

#### Session

```{r, echo = TRUE}
sessionInfo()
```

### References